dat1[[x]] <- log(dat1[[x]] + 1)
}
## Dropping perfectly collinear variables
dat2=dummy.data.frame(dat1,names=names(which(sapply(dat1,class)=='factor')))
drops=c('MoSoldQtrQ4','YearRemodeDecile(2007,2010]','YearBuiltCombinedOlder than 1900','SaleConditionPartial',
'SaleTypeWD','FenceNo Fence','PavedDriveY','GarageCondNo Garage','GarageCondTA','GarageQualTA','GarageQualNo Garage',
'GarageFinishNo Garage','FireplaceQuTA','FunctionalTyp','KitchenQualTA','X1stFlrSF','ElectricalSBrkr',
'CentralAirY','HeatingQCTA','HeatingWall','BsmtFinType2No Basement','BsmtFinType1No Basement','BsmtExposureNo Basement',
'BsmtCondNo Basement','FoundationWood','ExterCondPo','ExterQualTA','MasVnrTypeStone','Exterior2ndWd Shng',
'Exterior2ndCBlock','Exterior1stWdShing','RoofMatlWdShngl','RoofStyleShed','Condition1RRNn',
'NeighborhoodVeenker','LandSlopeSev','LotConfigInside','LandContourLvl','LotShapeReg','AlleyPave',
'MSZoningRM','BsmtFinType1Unf','BsmtQualTA','GarageFinishUnf','GarageTypeNo Garage','TotalBsmtSF','BsmtCondTA',
'Exterior1stAsphShn','BsmtExposureNo','HeatingFloor','HeatingQCPo','FunctionalSev','MSSubClass190',
'BldgTypeTwnhsE','BldgType2fmCon','BldgTypeDuplex')
dat2=dat2[, !(names(dat2) %in% drops) ]
library(hydroGOF)
library(glmnet)
library(dummies)
dat = train
dim(dat1)
dat2=dummy.data.frame(dat1,names=names(which(sapply(dat1,class)=='factor')))
dim(dat2)
dat2=dat2[, !(names(dat2) %in% drops) ]
dim(dat2)
smp_size <- floor(0.70 * nrow(dat2))
## set the seed to make your partition reproductible
set.seed(123)
train_ind <- sample(seq_len(nrow(dat2)), size = smp_size)
train <- dat2[train_ind, ]
test <- dat2[-train_ind, ]
test <- test[,!(names(test) %in% 'SalePrice')]
## Linear regression
model=lm(SalePrice~.,train)
pred_test=predict.lm(model,test)
pred_train=predict.lm(model,train[,!(names(train) %in% 'SalePrice')])
test_rmse=RMSE(dat2[-train_ind, ]$SalePrice,pred_test,wt=1) #21099
train_rmse=RMSE(dat2[train_ind, ]$SalePrice,pred_train,wt = 1) #17766
test_rmse
train_rmse
test_rmse=rmse(dat2[-train_ind, ]$SalePrice,pred_test) #21099
train_rmse=rmse(dat2[train_ind, ]$SalePrice,pred_train) #17766
train_rmse
test_rmse
grid=seq(1,0,-0.001)
set.seed(1)
ridge.mod=glmnet(as.matrix(train[,!(names(train) %in% 'SalePrice')]),train$SalePrice,alpha=0, lambda =grid ,
thresh =1e-12)
cv.out=cv.glmnet(as.matrix(train[,!(names(train) %in% 'SalePrice')]),train$SalePrice,alpha=0)
bestlam =cv.out$lambda.min #0.09013617
bestlam
ridge.pred_test=predict (ridge.mod ,s=bestlam ,newx=as.matrix(test))
ridge.pred_train=predict (ridge.mod ,s=bestlam ,newx=as.matrix(train[,!(names(train) %in% 'SalePrice')]))
test_rmse_ridge=rmse(exp(dat2[-train_ind, ]$SalePrice),exp(ridge.pred_test[,1])) #21099
train_rmse_ridge=rmse(exp(dat2[train_ind, ]$SalePrice),exp(ridge.pred_train[,1])) #17766
test_rmse_ridge
class(ridge.pred_train)
test_rmse_ridge=RMSE(dat2[-train_ind, ]$SalePrice,ridge.pred_test[,1],wt=1) #21099
train_rmse_ridge=RMSE(dat2[train_ind, ]$SalePrice,ridge.pred_train[,1],wt = 1) #17766
test_rmse_ridge
train_rmse_ridge
train = read.csv("../RAW/train.csv", header = TRUE)
test = read.csv("../RAW/test.csv", header = TRUE)
train=subset(train,train$GrLivArea<=4000)
train <- treat.missing.values(dat=train)
test <- treat.missing.values(dat=test)
# Binning some numeric variables and dropping the original cols
train$MSSubClass <- as.factor(train$MSSubClass)
test$MSSubClass <- as.factor(test$MSSubClass)
train <- data.table(train)
test <- data.table(test)
train <- bin.variables(dat=train)
test <- bin.variables(dat=test)
train <- misc.features(dat=train)
test <- misc.features(dat=test)
library(data.table)
library(mice)
library(dplyr)
train = read.csv("../RAW/train.csv", header = TRUE)
test = read.csv("../RAW/test.csv", header = TRUE)
train=subset(train,train$GrLivArea<=4000)
train <- treat.missing.values(dat=train)
test <- treat.missing.values(dat=test)
train$MSSubClass <- as.factor(train$MSSubClass)
test$MSSubClass <- as.factor(test$MSSubClass)
train <- data.table(train)
test <- data.table(test)
train <- bin.variables(dat=train)
test <- bin.variables(dat=test)
train <- misc.features(dat=train)
test <- misc.features(dat=test)
rmv.cols <- c("Id", "Street","Condition2", "MiscFeature",
"GarageYrBlt", 'PoolQC','PoolArea',"YearRemodAdd",
"YearBuilt", "Utilities", 'MoSold','HouseStyle')
dim(train);dim(test)
train[,(rmv.cols):=NULL]
test[,(rmv.cols):=NULL]
any(is.na(train))
any(is.na(test))
dim(train)
train_orig <- copy(train)
fm <- formula(paste("~ ",paste(colnames(train),collapse = "+"), sep = ""))
dummyObj = dummyVars(formula = fm, data = train, sep = NULL)
train <- predict(dummyObj,train)
train <- data.table(train)
model=lm(SalePrice~.,train)
cols_to_keep <- gsub("`","",rownames(summary(model)$coeff))
cols_to_keep <- cols_to_keep[-1]
train <- subset(train, select = c("SalePrice",cols_to_keep))
library(caret)
train = copy(train_orig)
fm <- formula(paste("~ ",paste(colnames(train),collapse = "+"), sep = ""))
dummyObj = dummyVars(formula = fm, data = train, sep = NULL)
train <- predict(dummyObj,train)
train <- data.table(train)
model=lm(SalePrice~.,train)
cols_to_keep <- gsub("`","",rownames(summary(model)$coeff))
cols_to_keep <- cols_to_keep[-1]
train <- subset(train, select = c("SalePrice",cols_to_keep))
dim(train)
set.seed(123)
indx = sample(1:nrow(train),0.3*nrow(train),replace = F)
val <- train[indx,]
train <- train[-indx,]
dim(train); dim(val);
library(glmnet)
y_train <- log(train[["SalePrice"]]+1)
x_train = copy(train)
x_train[,SalePrice:=NULL]
y_val <- log(val[["SalePrice"]]+1)
x_val = copy(val)
x_val[,SalePrice:=NULL]
grid=seq(1,0,-0.001)
set.seed(1)
ridge.mod=glmnet(as.matrix(x_train),y_train,alpha=0, lambda =grid)
cv.out=cv.glmnet(as.matrix(x_train),train$SalePrice,alpha=0)
cv.out$lambda.min
bestlam
cv.out=cv.glmnet(as.matrix(x_train),y_train,alpha=0)
cv.out$lambda.min
ridge.pred_test=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_val))
ridge.pred_train=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_train))
test_rmse_ridge=RMSE(y_val,ridge.pred_test,wt=1)
train_rmse_ridge=RMSE(y_train,ridge.pred_train,wt=1)
print(test_rmse_ridge)
print(train_rmse_ridge)
cp1
cp0
dim(train)
model=lm(log(SalePrice)~.,train)
summary(model)$coeff
summary(model)$coeff
summary(model)
train = read.csv("../RAW/train.csv", header = TRUE)
test = read.csv("../RAW/test.csv", header = TRUE)
train <- treat.missing.values(dat=train)
test <- treat.missing.values(dat=test)
# Binning some numeric variables and dropping the original cols
train$MSSubClass <- as.factor(train$MSSubClass)
test$MSSubClass <- as.factor(test$MSSubClass)
train <- data.table(train)
test <- data.table(test)
train <- bin.variables(dat=train)
test <- bin.variables(dat=test)
train <- misc.features(dat=train)
test <- misc.features(dat=test)
rmv.cols <- c("Id", "Street","Condition2", "MiscFeature",
"GarageYrBlt", 'PoolQC','PoolArea', "X1stFlrSF", "YearRemodAdd",
"YearBuilt", "Utilities", 'MoSold','HouseStyle')
dim(train);dim(test)
train[,(rmv.cols):=NULL]
test[,(rmv.cols):=NULL]
any(is.na(train))
any(is.na(test))
dim(train)
train_orig <- copy(train)
fm <- formula(paste("~ ",paste(colnames(train),collapse = "+"), sep = ""))
dummyObj = dummyVars(formula = fm, data = train, sep = NULL)
train <- predict(dummyObj,train)
train <- data.table(train)
dim(train)
model=lm(SalePrice~.,train)
cols_to_keep <- gsub("`","",rownames(summary(model)$coeff))
cols_to_keep <- cols_to_keep[-1]
train <- subset(train, select = c("SalePrice",cols_to_keep))
dim(train)
set.seed(123)
indx = sample(1:nrow(train),0.3*nrow(train),replace = F)
val <- train[indx,]
train <- train[-indx,]
# drop.cols = c("BsmtCond","ExterCond","GarageCond")
# train <- subset(train,select = !(colnames(train)%in% drop.cols))
# val <- subset(val,select = !(colnames(val)%in% drop.cols))
dim(train); dim(val);
library(glmnet)
y_train <- log(train[["SalePrice"]]+1)
x_train = copy(train)
x_train[,SalePrice:=NULL]
y_val <- log(val[["SalePrice"]]+1)
x_val = copy(val)
x_val[,SalePrice:=NULL]
grid=seq(1,0,-0.001)
set.seed(1)
ridge.mod=glmnet(as.matrix(x_train),y_train,alpha=0, lambda =grid)
cv.out=cv.glmnet(as.matrix(x_train),y_train,alpha=0)
bestlam =cv.out$lambda.min #0.09013617
bestlam
ridge.pred_test=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_val))
ridge.pred_train=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_train))
test_rmse_ridge=RMSE(y_val,ridge.pred_test,wt=1)
train_rmse_ridge=RMSE(y_train,ridge.pred_train,wt=1)
print(test_rmse_ridge)
print(train_rmse_ridge)
ridge.pred_test=predict (ridge.mod ,s=.137 ,newx=as.matrix(x_val))
ridge.pred_train=predict (ridge.mod ,s=.137 ,newx=as.matrix(x_train))
test_rmse_ridge=RMSE(y_val,ridge.pred_test,wt=1)
train_rmse_ridge=RMSE(y_train,ridge.pred_train,wt=1)
print(test_rmse_ridge)
print(train_rmse_ridge)
tail(colnames(x_train))
dim(x_train)
dim(x_val)
"SalePrice" %in% colnames(x_train)
tail(colnames(x_train),10)
source("./lib.R")
train = read.csv("../RAW/train.csv", header = TRUE)
test = read.csv("../RAW/test.csv", header = TRUE)
train=subset(train,train$GrLivArea<=4000)
train <- treat.missing.values(dat=train)
test <- treat.missing.values(dat=test)
# Binning some numeric variables and dropping the original cols
train$MSSubClass <- as.factor(train$MSSubClass)
test$MSSubClass <- as.factor(test$MSSubClass)
train <- data.table(train)
test <- data.table(test)
train <- bin.variables(dat=train)
test <- bin.variables(dat=test)
train <- misc.features(dat=train)
test <- misc.features(dat=test)
tail(colnames(train))
tail(colnames(train),10)
rmv.cols <- c("Id", "Street","Condition2", "MiscFeature",
"GarageYrBlt", 'PoolQC','PoolArea', "X1stFlrSF", "YearRemodAdd",
"YearBuilt", "Utilities", 'MoSold','HouseStyle')
dim(train);dim(test)
train[,(rmv.cols):=NULL]
test[,(rmv.cols):=NULL]
any(is.na(train))
any(is.na(test))
train_orig <- copy(train)
fm <- formula(paste("~ ",paste(colnames(train),collapse = "+"), sep = ""))
dummyObj = dummyVars(formula = fm, data = train, sep = NULL)
train <- predict(dummyObj,train)
train <- data.table(train)
model=lm(SalePrice~.,train)
cols_to_keep <- gsub("`","",rownames(summary(model)$coeff))
cols_to_keep <- cols_to_keep[-1]
train <- subset(train, select = c("SalePrice",cols_to_keep))
set.seed(123)
indx = sample(1:nrow(train),0.3*nrow(train),replace = F)
val <- train[indx,]
train <- train[-indx,]
library(glmnet)
y_train <- log(train[["SalePrice"]]+1)
x_train = copy(train)
x_train[,SalePrice:=NULL]
y_val <- log(val[["SalePrice"]]+1)
x_val = copy(val)
x_val[,SalePrice:=NULL]
grid=seq(1,0,-0.001)
set.seed(1)
ridge.mod=glmnet(as.matrix(x_train),y_train,alpha=0, lambda =grid)
cv.out=cv.glmnet(as.matrix(x_train),y_train,alpha=0)
cv.out$lambda.min
bestlam =cv.out$lambda.min #0.09013617
ridge.pred_test=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_val))
ridge.pred_train=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_train))
test_rmse_ridge=RMSE(y_val,ridge.pred_test,wt=1)
train_rmse_ridge=RMSE(y_train,ridge.pred_train,wt=1)
print(test_rmse_ridge)
print(train_rmse_ridge)
tail(colnames(x_train),10)
dim(x_train)
dim(train)
set.seed(1)
ridge.mod=glmnet(as.matrix(x_train[,1:245,with=F]),y_train,alpha=0, lambda =grid)
cv.out=cv.glmnet(as.matrix(x_train[,1:245,with=F]),y_train,alpha=0)
bestlam =cv.out$lambda.min #0.09013617
bestlam
ridge.pred_test=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_val[,1:245,with=F]))
ridge.pred_train=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_train[,1:245,with=F]))
test_rmse_ridge=RMSE(y_val,ridge.pred_test,wt=1)
train_rmse_ridge=RMSE(y_train,ridge.pred_train,wt=1)
print(test_rmse_ridge)
print(train_rmse_ridge)
ridge.mod=glmnet(as.matrix(x_train[,1:245,with=F]),y_train,alpha=0.5, lambda =grid)
cv.out=cv.glmnet(as.matrix(x_train[,1:245,with=F]),y_train,alpha=0.5)
set.seed(1)
ridge.mod=glmnet(as.matrix(x_train[,1:245,with=F]),y_train,alpha=0.5, lambda =grid)
cv.out=cv.glmnet(as.matrix(x_train[,1:245,with=F]),y_train,alpha=0.5)
bestlam =cv.out$lambda.min #0.09013617
bestlam
ridge.pred_test=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_val[,1:245,with=F]))
ridge.pred_train=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_train[,1:245,with=F]))
test_rmse_ridge=RMSE(y_val,ridge.pred_test,wt=1)
train_rmse_ridge=RMSE(y_train,ridge.pred_train,wt=1)
print(test_rmse_ridge)
print(train_rmse_ridge)
set.seed(1)
ridge.mod=glmnet(as.matrix(x_train[,1:245,with=F]),y_train,alpha=1, lambda =grid)
cv.out=cv.glmnet(as.matrix(x_train[,1:245,with=F]),y_train,alpha=1)
bestlam =cv.out$lambda.min #0.09013617
bestlam
ridge.pred_test=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_val[,1:245,with=F]))
ridge.pred_train=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_train[,1:245,with=F]))
test_rmse_ridge=RMSE(y_val,ridge.pred_test,wt=1)
train_rmse_ridge=RMSE(y_train,ridge.pred_train,wt=1)
print(test_rmse_ridge)
print(train_rmse_ridge)
grid=seq(1,0,-0.001)
set.seed(1)
ridge.mod=glmnet(as.matrix(x_train),y_train,alpha=1, lambda =grid)
cv.out=cv.glmnet(as.matrix(x_train),y_train,alpha=1)
bestlam =cv.out$lambda.min #0.09013617
ridge.pred_test=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_val))
ridge.pred_train=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_train))
test_rmse_ridge=RMSE(y_val,ridge.pred_test,wt=1)
train_rmse_ridge=RMSE(y_train,ridge.pred_train,wt=1)
print(test_rmse_ridge)
print(train_rmse_ridge)
train = read.csv("../RAW/train.csv", header = TRUE)
test = read.csv("../RAW/test.csv", header = TRUE)
source("./lib.R")
train=subset(train,train$GrLivArea<=4000)
train <- treat.missing.values(dat=train)
test <- treat.missing.values(dat=test)
# Binning some numeric variables and dropping the original cols
train$MSSubClass <- as.factor(train$MSSubClass)
test$MSSubClass <- as.factor(test$MSSubClass)
train <- data.table(train)
test <- data.table(test)
train <- bin.variables(dat=train)
test <- bin.variables(dat=test)
train <- misc.features(dat=train)
test <- misc.features(dat=test)
rmv.cols <- c("Street","Condition2", "MiscFeature",
"GarageYrBlt", 'PoolQC','PoolArea', "X1stFlrSF", "YearRemodAdd",
"YearBuilt", "Utilities", 'MoSold','HouseStyle')
dim(train);dim(test)
train[,(rmv.cols):=NULL]
test[,(rmv.cols):=NULL]
any(is.na(train))
any(is.na(test))
library(mice)
colnames(test)[unlist(lapply(colnames(test), function(x){any(is.na(test[,get(x)]))}))]
test_impute <- mice(test[,c("MSZoning","Exterior1st","Exterior2nd","Functional",
"SaleType"), with=F], m=1,  method = "cart",
seed=123, maxit = 100, printFlag = F )
for(n in names(test_impute$imp)){
x = test_impute$imp[[n]][,1]
test[is.na(get(n)),(n):=x]
}
test$num_ext_materials <- ifelse(as.character(test$Exterior1st)==as.character(test$Exterior2nd),1,2)
dim(train)
dim(test)
train_orig <- copy(train)
fm <- formula(paste("~ ",paste(colnames(train),collapse = "+"), sep = ""))
dummyObj = dummyVars(formula = fm, data = train, sep = NULL)
train <- predict(dummyObj,train)
train <- data.table(train)
model=lm(SalePrice~.,train)
cols_to_keep <- gsub("`","",rownames(summary(model)$coeff))
cols_to_keep <- cols_to_keep[-1]
train <- subset(train, select = c("SalePrice",cols_to_keep))
set.seed(123)
indx = sample(1:nrow(train),0.3*nrow(train),replace = F)
val <- train[indx,]
train <- train[-indx,]
dim(train); dim(val);
library(glmnet)
y_train <- log(train[["SalePrice"]]+1)
x_train = copy(train)
x_train[,":="(SalePrice=NULL, Id =NULL)]
y_val <- log(val[["SalePrice"]]+1)
x_val = copy(val)
x_val[,":="(SalePrice=NULL, Id =NULL)]
grid=seq(1,0,-0.001)
set.seed(1)
ridge.mod=glmnet(as.matrix(x_train),y_train,alpha=1, lambda =grid)
cv.out=cv.glmnet(as.matrix(x_train),y_train,alpha=1)
bestlam =cv.out$lambda.min #0.09013617
bestlam
ridge.pred_test=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_val))
ridge.pred_train=predict (ridge.mod ,s=bestlam ,newx=as.matrix(x_train))
test_rmse_ridge=RMSE(y_val,ridge.pred_test,wt=1)
train_rmse_ridge=RMSE(y_train,ridge.pred_train,wt=1)
print(test_rmse_ridge)
print(train_rmse_ridge)
train = copy(train_orig)
train <- predict(dummyObj,train)
train <- data.table(train)
train <- subset(train, select = c("SalePrice",cols_to_keep))
dim(train)
test <- predict(dummyObj,test)
test <- data.table(test)
dim(test)
dim(train_orig)
y_train <- log(train[["SalePrice"]]+1)
x_train = copy(train)
x_train[,":="(SalePrice=NULL, Id =NULL)]
grid=seq(1,0,-0.001)
set.seed(1)
ridge.mod=glmnet(as.matrix(x_train),y_train,alpha=1, lambda =grid)
cv.out=cv.glmnet(as.matrix(x_train),y_train,alpha=1)
#plot(cv.out)
bestlam =cv.out$lambda.min
bestlam
fm <- formula(paste("~ ",paste(colnames(test),collapse = "+"), sep = ""))
dummyObj = dummyVars(formula = fm, data = test, sep = NULL)
test <- predict(dummyObj,test)
test <- data.table(test)
dim(train)
dim(test)
dim(x_test)
dim(x_train)
all(colnames(test) %in% colnames(train))
all(colnames(train) %in% colnames(test))
which(!(colnames(train) %in% colnames(test)))
colnames(train)[which(!(colnames(train) %in% colnames(test)))]
train = copy(train_orig)
dim(train)
target = train$target
train[,target:=NULL]
fm <- formula(paste("~ ",paste(colnames(train),collapse = "+"), sep = ""))
dummyObj = dummyVars(formula = fm, data = train, sep = NULL)
train <- predict(dummyObj,train)
train$SalePrice = target
train <- data.table(train)
train = copy(train_orig)
target = train$target
train[,SalePrice:=NULL]
fm <- formula(paste("~ ",paste(colnames(train),collapse = "+"), sep = ""))
dummyObj = dummyVars(formula = fm, data = train, sep = NULL)
train <- predict(dummyObj,train)
train$SalePrice = target
train <- data.table(train)
class(target)
train = copy(train_orig)
target = train$SalePrice
train[,SalePrice:=NULL]
fm <- formula(paste("~ ",paste(colnames(train),collapse = "+"), sep = ""))
dummyObj = dummyVars(formula = fm, data = train, sep = NULL)
train <- predict(dummyObj,train)
train$SalePrice = target
train <- data.table(train)
train = copy(train_orig)
target = train$SalePrice
class(tagrget)
class(target)
dim(train)
train[,SalePrice:=NULL]
fm <- formula(paste("~ ",paste(colnames(train),collapse = "+"), sep = ""))
dummyObj = dummyVars(formula = fm, data = train, sep = NULL)
train <- predict(dummyObj,train)
train[,SalePrice:=NULL]
dim(train)
train <- data.table(train)
train$SalePrice = target
train = read.csv("../RAW/train.csv", header = TRUE)
test = read.csv("../RAW/test.csv", header = TRUE)
source("./lib.R")
train=subset(train,train$GrLivArea<=4000)
train <- treat.missing.values(dat=train)
test <- treat.missing.values(dat=test)
# Binning some numeric variables and dropping the original cols
train$MSSubClass <- as.factor(train$MSSubClass)
test$MSSubClass <- as.factor(test$MSSubClass)
train <- data.table(train)
test <- data.table(test)
train <- bin.variables(dat=train)
test <- bin.variables(dat=test)
train <- misc.features(dat=train)
test <- misc.features(dat=test)
rmv.cols <- c("Street","Condition2", "MiscFeature",
"GarageYrBlt", 'PoolQC','PoolArea', "X1stFlrSF", "YearRemodAdd",
"YearBuilt", "Utilities", 'MoSold','HouseStyle')
dim(train);dim(test)
train[,(rmv.cols):=NULL]
test[,(rmv.cols):=NULL]
any(is.na(train))
any(is.na(test))
colnames(test)[unlist(lapply(colnames(test), function(x){any(is.na(test[,get(x)]))}))]
for(n in names(test_impute$imp)){
x = test_impute$imp[[n]][,1]
test[is.na(get(n)),(n):=x]
}
test$num_ext_materials <- ifelse(as.character(test$Exterior1st)==as.character(test$Exterior2nd),1,2)
train_orig <- copy(train)
target = train$SalePrice
train[,SalePrice:=NULL]
fm <- formula(paste("~ ",paste(colnames(train),collapse = "+"), sep = ""))
dummyObj = dummyVars(formula = fm, data = train, sep = NULL)
train <- predict(dummyObj,train)
train <- data.table(train)
train$SalePrice = target
test_orig = copy(test)
dim(train)
test <- predict(dummyObj,test)
dim(train_rmse)
dim(test)
dim(train_orig)
unique(train_orig$MSSubClass)
unique(test$MSSubClass)
